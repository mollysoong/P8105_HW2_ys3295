Homework 2
================
Yan Song

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

First, define a path to the dataset.

``` r
path_to_data = "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx"
```

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
    read_xlsx(
        path = path_to_data,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
    )
```

Read precipitation data\! For 2018 and 2017.

``` r
precip_2018 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx",
        sheet = "2018 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2018) %>% 
    relocate(year)

precip_2017 = 
    read_excel(
        "./data/Trash-Wheel-Collection-Totals-7-2020-1.xlsx",
        sheet = "2017 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2017) %>% 
    relocate(year)
```

Now combine annual precipitation dataframes. In the following code
chunk, I create a “helper” tibble that contains pairs of numeric and
character ways of representing month, and then merge that (using month
number as a key) with the precipitation dataset. This technique is one I
use often when I need to recode a moderate or large number of values for
a variable.

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )

precip_df = 
    bind_rows(precip_2018, precip_2017)

precip_df =
    left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 416 rows in our final
dataset. Additional data sheets include month precipitation data. In
this dataset:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

## Problem 2

Read and clean NYC Transit data.

``` r
nyc_transit_df = read.csv ("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na.strings = c("","NA")) %>% 
janitor::clean_names() %>% 
select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE), 
       entry = as.logical(entry))
```

Description

The NYC transit data contains information related to each entrance and
exit for each subway station in NYC. The resulting dataset contains
information on line, station name, station latitude, station logitude,
routes served, entry, vending, entrance type and ADA compliance.And the
entry variable is converted from character to logical variable. The
dimension of the resulting data is 1868 x 19.

``` r
# Question 1
station_num = distinct(nyc_transit_df, line, station_name)

# Question 2
ada_num = distinct(nyc_transit_df, line, station_name,ada) %>% filter(ada == TRUE)

# Question 3
no_vending_num = nyc_transit_df %>%
  filter(vending == 'NO', entry == TRUE)
entry_num = nyc_transit_df %>%
  filter(vending == 'NO')

no_vending_prop = nrow(no_vending_num)/nrow(entry_num)*100
```

  - There are 465 distinct stations.
  - There are 84 stations are ADA compliant.
  - The proportion of station entrance/ exits without vending allow
    entrance is 37.7%.

<!-- end list -->

``` r
nyc_transit_tidy = nyc_transit_df %>%
  mutate (route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>%
  pivot_longer (
    route1:route11,
    names_to = "route_name",
    values_to = "route_num")
```

  - There are 60 distinct stations serve the A train. Of the stations
    that serve the A train, there are 17 ADA compliant.

## Problem 3

First, we read and clean the data in pols-month.csv.

``` r
pols_month = read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.abb[month],
    president = ifelse(prez_gop == 1, "republican", "democratic")
    ) %>% 
  select(-prez_gop, -prez_dem, -day) %>% 
  arrange(year, month) 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Second, we read and clean the data in snp.csv.

``` r
snp = read_csv(file = "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"),sep = "/") %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.abb[month]
  ) %>% 
  select(year, month, everything(),-day) 
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Third, we read and tidy the umemployment data.

``` r
unemployment = read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>%
  pivot_longer(
    "jan":"dec",
    names_to = "month",
    values_to = "unemployment_percentage"
  ) %>% 
  arrange(year, month) 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Then, we combine the above three datasets together.

``` r
pols = 
  left_join(pols_month, snp) 
```

    ## Joining, by = c("year", "month")

``` r
pols_tidy = 
  left_join(pols, unemployment)
```

    ## Joining, by = c("year", "month")

Description

  - There are 822 rows and 10 columns in the pols\_month dataset. The
    key variable which contains row keys is year and month in this
    dataset. The range of years of the pols\_dataset is (1947, 2015).

  - There are 787 rows and 3 columns in the snp dataset. The key
    variable which contains row keys is year and month in this dataset.
    The range of years of the pols\_dataset is (1950, 2015).

  - There are 816 rows and 3 columns in the employment data. The key
    variable which contains row keys is year and month in this dataset.
    The range of years of the pols\_dataset is (1948, 2015).
